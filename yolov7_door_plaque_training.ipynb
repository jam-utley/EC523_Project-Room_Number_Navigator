{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAN5LkS9WA5i"
      },
      "source": [
        "# YOLOv7 Door Plaque Detection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPUKB-1AWA5k"
      },
      "source": [
        "Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnzduTJgWA5l"
      },
      "outputs": [],
      "source": [
        "# Verify GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fSbqe1rWA5l"
      },
      "outputs": [],
      "source": [
        "# Navigate to content directory and set up workspace\n",
        "%cd /content\n",
        "\n",
        "# Remove any existing yolov7 folder\n",
        "!rm -rf yolov7\n",
        "\n",
        "print(\"Workspace prepared\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw59lUTFWA5m"
      },
      "source": [
        "Upload Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1uFR2NhWA5m"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload the zip file\n",
        "print(\"Please upload your dataset ZIP file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\n Extracting {zip_filename}...\")\n",
        "\n",
        "    # Extract\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/dataset')\n",
        "\n",
        "    # Find actual dataset path\n",
        "    dataset_contents = os.listdir('/content/dataset')\n",
        "    if len(dataset_contents) == 1 and os.path.isdir(f'/content/dataset/{dataset_contents[0]}'):\n",
        "        DATASET_PATH = f'/content/dataset/{dataset_contents[0]}'\n",
        "    else:\n",
        "        DATASET_PATH = '/content/dataset'\n",
        "\n",
        "    print(f\"Dataset extracted to: {DATASET_PATH}\")\n",
        "else:\n",
        "    print(\"No file uploaded. Please run this cell again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFXZ5ht-WA5n"
      },
      "source": [
        "Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYK2HGnSWA5n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check dataset exists\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    print(f\"ERROR: Dataset not found at {DATASET_PATH}\")\n",
        "else:\n",
        "    print(f\"Dataset found at: {DATASET_PATH}\\n\")\n",
        "\n",
        "    # Count images\n",
        "    def count_images(folder_path):\n",
        "        if not os.path.exists(folder_path):\n",
        "            return 0\n",
        "        return len([f for f in os.listdir(folder_path)\n",
        "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "    train_imgs = count_images(os.path.join(DATASET_PATH, 'train/images'))\n",
        "    val_imgs = count_images(os.path.join(DATASET_PATH, 'valid/images'))\n",
        "    test_imgs = count_images(os.path.join(DATASET_PATH, 'test/images'))\n",
        "\n",
        "    print(\"Dataset Summary:\")\n",
        "    print(f\"  Training:   {train_imgs} images\")\n",
        "    print(f\"  Validation: {val_imgs} images\")\n",
        "    print(f\"  Test:       {test_imgs} images\")\n",
        "    print(f\"  Total:      {train_imgs + val_imgs + test_imgs} images\")\n",
        "\n",
        "    if train_imgs == 472 and val_imgs == 100 and test_imgs == 20:\n",
        "        print(\"\\n Image counts match expected values!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBlSqIOvWA5n"
      },
      "outputs": [],
      "source": [
        "# Clone YOLOv7\n",
        "%cd /content\n",
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7\n",
        "\n",
        "print(\"YOLOv7 cloned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zip3UoLdWA5n"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q matplotlib>=3.2.2\n",
        "!pip install -q numpy>=1.18.5\n",
        "!pip install -q opencv-python>=4.1.2\n",
        "!pip install -q Pillow>=7.1.2\n",
        "!pip install -q PyYAML>=5.3.1\n",
        "!pip install -q requests>=2.23.0\n",
        "!pip install -q scipy>=1.4.1\n",
        "!pip install -q tqdm>=4.41.0\n",
        "!pip install -q tensorboard>=2.4.1\n",
        "!pip install -q pandas>=1.1.4\n",
        "!pip install -q seaborn>=0.11.0\n",
        "\n",
        "print(\"Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhRpHKvzWA5n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def fix_torch_load(filepath):\n",
        "    \"\"\"Add weights_only=False to torch.load calls\"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        return False\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    original = content\n",
        "\n",
        "    patterns = [\n",
        "        (r\"torch\\.load\\(([^,]+), map_location=([^)]+)\\)(?!.*weights_only)\",\n",
        "         r\"torch.load(\\1, map_location=\\2, weights_only=False)\"),\n",
        "        (r\"torch\\.load\\(cache_path\\)(?!.*weights_only)\",\n",
        "         r\"torch.load(cache_path, weights_only=False)\"),\n",
        "        (r\"torch\\.load\\(f, map_location=torch\\.device\\('cpu'\\)\\)(?!.*weights_only)\",\n",
        "         r\"torch.load(f, map_location=torch.device('cpu'), weights_only=False)\"),\n",
        "    ]\n",
        "\n",
        "    for pattern, replacement in patterns:\n",
        "        content = re.sub(pattern, replacement, content)\n",
        "\n",
        "    if content != original:\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "files_to_fix = [\n",
        "    'train.py',\n",
        "    'test.py',\n",
        "    'detect.py',\n",
        "    'models/experimental.py',\n",
        "    'utils/datasets.py',\n",
        "    'utils/general.py'\n",
        "]\n",
        "\n",
        "\n",
        "for filepath in files_to_fix:\n",
        "    if fix_torch_load(filepath):\n",
        "        print(f\"Fixed: {filepath}\")\n",
        "    else:\n",
        "        print(f\"‚è≠Skipped: {filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IPbchfNWA5o"
      },
      "outputs": [],
      "source": [
        "# Download pre-trained weights\n",
        "!wget -q https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
        "\n",
        "if os.path.exists('yolov7.pt'):\n",
        "    print(\"Downloaded yolov7.pt\")\n",
        "else:\n",
        "    print(\"Failed to download weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6tW8YntWA5o"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "data_yaml_path = os.path.join(DATASET_PATH, 'data.yaml')\n",
        "\n",
        "if os.path.exists(data_yaml_path):\n",
        "    # Read current config\n",
        "    with open(data_yaml_path, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "\n",
        "    print(\"Current data.yaml:\")\n",
        "    print(yaml.dump(data_config, default_flow_style=False))\n",
        "\n",
        "    # Update to absolute paths\n",
        "    data_config['train'] = os.path.join(DATASET_PATH, 'train/images')\n",
        "    data_config['val'] = os.path.join(DATASET_PATH, 'valid/images')\n",
        "    data_config['test'] = os.path.join(DATASET_PATH, 'test/images')\n",
        "\n",
        "    # Save updated config\n",
        "    with open(data_yaml_path, 'w') as f:\n",
        "        yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "    print(\"\\n Updated data.yaml with absolute paths\")\n",
        "    print(\"\\nNew configuration:\")\n",
        "    print(yaml.dump(data_config, default_flow_style=False))\n",
        "else:\n",
        "    print(f\"data.yaml not found at {data_yaml_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZnHFCDRWA5o"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "EPOCHS = 75           # Number of epochs\n",
        "BATCH_SIZE = 16        # Batch size\n",
        "IMG_SIZE = 640         # Image size\n",
        "WEIGHTS = 'yolov7.pt'  # Pre-trained weights\n",
        "PROJECT_NAME = 'door_plaque_detector'\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "print(f\"  Epochs:      {EPOCHS}\")\n",
        "print(f\"  Batch Size:  {BATCH_SIZE}\")\n",
        "print(f\"  Image Size:  {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"  Pre-trained: {WEIGHTS}\")\n",
        "print(f\"  Project:     {PROJECT_NAME}\")\n",
        "\n",
        "# Disable wandb\n",
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "print(\"\\n Configuration ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH7mFOCHWA5o"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDlC742MWA5o"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "!python train.py \\\n",
        "    --workers 8 \\\n",
        "    --device 0 \\\n",
        "    --batch-size {BATCH_SIZE} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --img {IMG_SIZE} {IMG_SIZE} \\\n",
        "    --data {data_yaml_path} \\\n",
        "    --hyp data/hyp.scratch.p5.yaml \\\n",
        "    --cfg cfg/training/yolov7.yaml \\\n",
        "    --weights {WEIGHTS} \\\n",
        "    --name {PROJECT_NAME} \\\n",
        "    --cache-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LM44MomWA5o"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Find the trained model\n",
        "train_dirs = glob.glob(f'runs/train/{PROJECT_NAME}*')\n",
        "\n",
        "if train_dirs:\n",
        "    # Get the most recent\n",
        "    latest_dir = max(train_dirs, key=os.path.getctime)\n",
        "    BEST_WEIGHTS = os.path.join(latest_dir, 'weights/best.pt')\n",
        "    LAST_WEIGHTS = os.path.join(latest_dir, 'weights/last.pt')\n",
        "\n",
        "    # Convert to absolute path\n",
        "    BEST_WEIGHTS = os.path.abspath(BEST_WEIGHTS)\n",
        "    LAST_WEIGHTS = os.path.abspath(LAST_WEIGHTS)\n",
        "\n",
        "    print(f\" Training completed!\\n\")\n",
        "    print(f\" Results directory: {latest_dir}\")\n",
        "    print(f\" Best weights: {BEST_WEIGHTS}\")\n",
        "    print(f\" Last weights: {LAST_WEIGHTS}\")\n",
        "\n",
        "    # Verify files exist\n",
        "    if os.path.exists(BEST_WEIGHTS):\n",
        "        print(\"\\n Weights file verified!\")\n",
        "    else:\n",
        "        print(\"\\n Warning: Weights file not found\")\n",
        "else:\n",
        "    print(\" No training runs found. Please complete training first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XYrnrFeWA5o"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "if 'latest_dir' in locals():\n",
        "    print(\" Training Results:\\n\")\n",
        "\n",
        "    results_img = os.path.join(latest_dir, 'results.png')\n",
        "    if os.path.exists(results_img):\n",
        "        display(Image(filename=results_img, width=900))\n",
        "    else:\n",
        "        print(\"Results plot not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk3Vztq6WA5o"
      },
      "outputs": [],
      "source": [
        "# Show confusion matrix\n",
        "if 'latest_dir' in locals():\n",
        "    print(\" Confusion Matrix:\\n\")\n",
        "\n",
        "    confusion_img = os.path.join(latest_dir, 'confusion_matrix.png')\n",
        "    if os.path.exists(confusion_img):\n",
        "        display(Image(filename=confusion_img, width=600))\n",
        "    else:\n",
        "        print(\"Confusion matrix not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZHOil7TWA5o"
      },
      "outputs": [],
      "source": [
        "# Run evaluation on test set\n",
        "if 'BEST_WEIGHTS' in locals() and os.path.exists(BEST_WEIGHTS):\n",
        "    !python test.py \\\n",
        "        --data {data_yaml_path} \\\n",
        "        --img 640 \\\n",
        "        --batch 16 \\\n",
        "        --conf 0.001 \\\n",
        "        --iou 0.65 \\\n",
        "        --device 0 \\\n",
        "        --weights {BEST_WEIGHTS} \\\n",
        "        --name test_evaluation \\\n",
        "        --verbose\n",
        "else:\n",
        "    print(\"Weights not found. Please complete training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZdSlMUKWA5o"
      },
      "source": [
        "Run Inference on Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YIdClA2WA5o"
      },
      "outputs": [],
      "source": [
        "# Detect on test images\n",
        "if 'BEST_WEIGHTS' in locals() and os.path.exists(BEST_WEIGHTS):\n",
        "    test_images = os.path.join(DATASET_PATH, 'test/images')\n",
        "\n",
        "    !python detect.py \\\n",
        "        --weights {BEST_WEIGHTS} \\\n",
        "        --conf 0.25 \\\n",
        "        --img-size 640 \\\n",
        "        --source {test_images} \\\n",
        "        --name test_detections \\\n",
        "        --save-txt \\\n",
        "        --save-conf\n",
        "\n",
        "    print(\"\\n Detections saved to: runs/detect/test_detections/\")\n",
        "else:\n",
        "    print(\" Weights not found. Please complete training first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7tD1c0PWA5o"
      },
      "outputs": [],
      "source": [
        "# Display sample detections\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "detection_dir = 'runs/detect/test_detections'\n",
        "if os.path.exists(detection_dir):\n",
        "    detection_imgs = glob.glob(f'{detection_dir}/*.jpg') + glob.glob(f'{detection_dir}/*.png')\n",
        "\n",
        "    print(f\" Showing 5 sample detections (out of {len(detection_imgs)} total):\\n\")\n",
        "\n",
        "    for img_path in detection_imgs[:5]:\n",
        "        print(f\"\\n{os.path.basename(img_path)}:\")\n",
        "        display(Image(filename=img_path, width=700))\n",
        "else:\n",
        "    print(\"No detections found. Run the detection cell above first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK9sOEErWA5r"
      },
      "source": [
        "Download Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYgsPlLmWA5r"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "if 'BEST_WEIGHTS' in locals() and os.path.exists(BEST_WEIGHTS):\n",
        "    print(\" Downloading trained model...\\n\")\n",
        "    files.download(BEST_WEIGHTS)\n",
        "    print(\"\\n Model downloaded!\")\n",
        "    print(f\"\\nYou can use this model file for inference in your applications.\")\n",
        "else:\n",
        "    print(\" No weights to download. Complete training first.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}